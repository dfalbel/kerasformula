Plan for Day
================
Pete
8/16/2018

### 9-9:15 Meet & Greet

### 9:15-10 Lecture 1: Overview & Learning Goals

leads into Demo 1 ... walk through install (if need be); introduce data; demonstrate basic of `kerasformula` functionality

[Lecture 1 link](https://web.stanford.edu/~pmohanty/kerasformula_lecture1.pdf)

### 10-10:30 Lab 1: 'hello kerasformula'

Participants answer quick questions in [Lab1.md](https://github.com/rdrr1990/kerasformula/blob/master/short_course/kerasformula_lab1.md) which highlight structure of input and output.

### 10:30-10:45 Break

### 10:45-11:15 Lecture 2: Key Elements of Neural Nets

[Lecture 2 link](https://web.stanford.edu/~pmohanty/kerasformula_lecture2.pdf)

### 11:15-Noon Lab 2: Design your own Neural Net

Participants build their own neural net using their own data and answer short questions found in [Lab2.md](https://github.com/rdrr1990/kerasformula/blob/master/short_course/kerasformula_lab2.md) which prompts them to estimate several models, take notes on output, etc.

(Participants should have a sample of their own data in a `data.frame` which is clean enough to run a regression on. Alternatively, code will be provided to quickly construct such a `data.frame` too and which will be similar to the data used in the slides.)

### Noon-1 Lunch

### 1-1:30 Lecture 3: Avoiding Overfitting with kerasformula

[Lecture 3 link](https://web.stanford.edu/~pmohanty/kerasformula_lecture3.pdf)

### 1:30-2 Lab 3: Triage against overfitting

Complete [Lab3.md](https://github.com/rdrr1990/kerasformula/blob/master/short_course/kerasformula_lab3.md)

### 2-2:15 Break

### 2:15-3:00 Lecture 4: Text as Data with kerasformula

Data reduction of text counts/ranks via embedding with troll tweets as data...

[Lecture 4 link](https://web.stanford.edu/~pmohanty/kerasformula_lecture4.pdf)

### 3:00-3:30 Lab 4: Congressional Text as Data

Participants complete text as data [lab4.md](https://github.com/rdrr1990/kerasformula/blob/master/short_course/kerasformula_lab4.md) with provided data (if latter more amendable to working with counts / ranks of text).

### 3:30-3:45 Break

### 3:45-4:15 Lecture 5: Advanced Neural Nets in Keras

[Lecture 5 link](https://web.stanford.edu/~pmohanty/kerasformula_lecture5.pdf)

### 4:15-5 Lecture 6 + Discussion: Promises and Pitfalls of Neural Nets for Political Research

[Lecture 6 link](https://web.stanford.edu/~pmohanty/kerasformula_lecture6.pdf)
